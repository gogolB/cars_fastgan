# Main configuration file for CARS-FASTGAN

defaults:
  - data: cars_dataset
  - model: fastgan
  - training: default
  - evaluation: default
  - _self_

# Global settings
project_name: "cars-fastgan"
experiment_name: "fastgan_baseline"
seed: 42

# Paths
data_path: "data/raw"
output_dir: "outputs"
checkpoint_dir: "experiments/checkpoints"
log_dir: "experiments/logs"

# Hardware settings
device: "auto"
accelerator: "auto"
devices: 1
precision: "32-true"

# Training settings (moved from training config for main.py compatibility)
max_epochs: 1000
min_epochs: 1
val_check_interval: 1.0
check_val_every_n_epoch: 10
log_every_n_steps: 50
log_images_every_n_epochs: 25
num_sample_images: 16

# Gradient clipping
gradient_clip_val: 1.0
gradient_clip_algorithm: "norm"
accumulate_grad_batches: 1

# Callbacks
callbacks:
  model_checkpoint:
    monitor: "val/d_loss"
    mode: "min"
    save_top_k: 3
    filename: "fastgan-{epoch:04d}-{val_d_loss:.3f}"
    auto_insert_metric_name: false
  early_stopping:
    monitor: "val/d_loss"
    mode: "min"
    patience: 200
    min_delta: 0.001
  lr_monitor:
    logging_interval: "epoch"
    log_momentum: false
  rich_progress_bar:
    leave: true
  model_summary:
    max_depth: 2

# Experiment tracking
use_wandb: false
wandb:
  project: "cars-fastgan"
  entity: null
  tags: ["fastgan", "cars", "microscopy", "thyroid"]
  log_model: true
  offline: false

# Debug settings
debug:
  fast_dev_run: false
  limit_train_batches: null
  limit_val_batches: null
  overfit_batches: 0

# Training stability
enable_checkpointing: true
enable_model_summary: true
enable_progress_bar: true
detect_anomaly: false
deterministic: true
benchmark: false

# Logging
log_level: "INFO"
save_last: true
monitor: "val/d_loss"
mode: "min"

# Profiling
profiler: null
num_sanity_val_steps: 2
reload_dataloaders_every_n_epochs: 0

# GAN-specific (for compatibility with training configs)
gan_training:
  fixed_noise_size: 64
  warmup_epochs: 10
  warmup_lr_factor: 0.1
  discriminator_warmup: 5
  generator_skip_threshold: 0.8
  loss_smoothing_window: 100
  loss_balance_threshold: 0.1
  adaptive_lr: false
  lr_adaptation_window: 50
  lr_adaptation_factor: 0.5